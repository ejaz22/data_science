{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced dataset techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Minority Over sampling Technique (SMOTE)\n",
    "\n",
    "this alogrithm applies KNN approach where it selects K nearest neighbors, joins them and creates the synthetic samples in the space. The algorithm takes the feature vectors and its nearest neighbors, computes the distance between these vectors. The difference is multiplied by random number between (0, 1) and it is added back to feature. SMOTE algorithm is a pioneer algorithm and many other algorithms are derived from SMOTE.\n",
    "\n",
    "## ADAptive SYNthetic (ADASYN)  \n",
    "\n",
    "It is based on the idea of adaptively generating minority data samples according to their distributions using K nearest neighbor. The algorithm adaptively updates the distribution and there are no assumptions made for the underlying distribution of the data.  The algorithm uses Euclidean distance for KNN Algorithm. The key difference between ADASYN and SMOTE is that the former uses a density distribution, as a criterion to automatically decide the number of synthetic samples that must be generated for each minority sample by adaptively changing the weights of the different minority samples to compensate for the skewed distributions. The latter generates the same number of synthetic samples for each original minority sample.\n",
    "\n",
    "## ANS: \n",
    "\n",
    "Adaptive Neighbor Synthetic (ANS) dynamically adapts the number of neighbors needed for oversampling around different minority regions. This algorithm eliminates the parameter K of SMOTE for a dataset and assign different number of neighbors for each positive instance. Every parameter for this technique is automatically set within the algorithm making it become parameter free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics specific to imbalanced learning\n",
    "Specific metrics have been developed to evaluate classifier which has been trained using imbalanced data. imblearn provides mainly two additional metrics which are not implemented in sklearn: \n",
    "- (i) geometric mean and \n",
    "- (ii) index balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distributions summary: Counter({2: 593, 1: 584, 0: 480, 3: 377})\n",
      "Test class distributions summary: Counter({2: 394, 1: 389, 0: 319, 3: 251})\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     categories=categories)\n",
    "\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "print('Training class distributions summary: {}'.format(Counter(y_train)))\n",
    "print('Test class distributions summary: {}'.format(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.67      0.94      0.86      0.79      0.90      0.82       319\n",
      "          1       0.96      0.92      0.99      0.94      0.95      0.90       389\n",
      "          2       0.87      0.98      0.94      0.92      0.96      0.92       394\n",
      "          3       0.97      0.36      1.00      0.52      0.60      0.33       251\n",
      "\n",
      "avg / total       0.87      0.84      0.94      0.82      0.88      0.78      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.70      0.90      0.88      0.78      0.89      0.79       319\n",
      "          1       0.96      0.85      0.99      0.90      0.91      0.82       389\n",
      "          2       0.95      0.86      0.98      0.90      0.92      0.83       394\n",
      "          3       0.76      0.74      0.95      0.75      0.84      0.68       251\n",
      "\n",
      "avg / total       0.86      0.84      0.95      0.85      0.89      0.79      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The recallof categroy 3 is low\n",
    "\n",
    "# using randomsamler\n",
    "pipe = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         RandomUnderSampler(),\n",
    "                         MultinomialNB())\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the recall of  3 has increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327330134981634"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_mean_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
