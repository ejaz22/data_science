{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Topic Modeling\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDAâ€™s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.hdpmodel import HdpModel # Heirarichal Dirichlet process\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "         ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "         ['eps', 'user', 'interface', 'system'],\n",
    "         ['system', 'human', 'system', 'eps'],\n",
    "         ['user', 'response', 'time'],\n",
    "         ['trees'],\n",
    "         ['graph', 'trees'],\n",
    "         ['graph', 'minors', 'trees'],\n",
    "         ['graph', 'minors', 'survey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(texts, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[texts], threshold=100)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus.\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] # # Term Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 50 iteration\n",
    "goodLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=50, num_topics=2)\n",
    "\n",
    "# one iteration ony\n",
    "badLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=1, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Coherence\n",
    "Topic Coherence is a measure used to evaluate topic models: methods that automatically generate topics from a collection of documents, using latent variable models.\n",
    "Each such generated topic consists of words, and the topic coherence is applied to the top N words from the topic. It is defined as the average / median of the pairwise word-similarity scores of the words in the topic (e.g. PMI).\n",
    "\n",
    "A good model will generate coherent topics, i.e., topics with high topic coherence scores. Good topics are topics that can be described by a short label, therefore this is what the topic coherence measure should capture.\n",
    "\n",
    "I'm not an expert, but I think the scores are mainly comparative: if topic B has a higher coherence score than topic A, it is 'better' (more coherent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3838413553737203 0.3838413553737203\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "print(goodcm.get_coherence(),badcm.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.664627001047737 -14.726061108336854\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "print(goodcm.get_coherence(),badcm.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0212114083512485"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "goodLdaModel.log_perplexity(corpus)  # a measure of how good the model is. lower the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize topic models\n",
    "\n",
    "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "\n",
    "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el112683388575686676029782\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el112683388575686676029782_data = {\"mdsDat\": {\"x\": [0.054002955555915826, -0.054002955555915826], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [63.32815170288086, 36.67184829711914]}, \"tinfo\": {\"Term\": [\"graph\", \"trees\", \"minors\", \"survey\", \"system\", \"computer\", \"user\", \"interface\", \"eps\", \"human\", \"response\", \"time\", \"system\", \"user\", \"eps\", \"response\", \"time\", \"human\", \"interface\", \"computer\", \"survey\", \"minors\", \"trees\", \"graph\", \"graph\", \"trees\", \"minors\", \"survey\", \"computer\", \"interface\", \"human\", \"time\", \"response\", \"eps\", \"user\", \"system\"], \"Freq\": [2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.3122706413269043, 2.5563108921051025, 1.8611172437667847, 1.7461594343185425, 1.7360107898712158, 1.423402190208435, 1.338363766670227, 1.1913222074508667, 1.043988585472107, 0.685613751411438, 0.8057540655136108, 0.6648480892181396, 1.868173360824585, 1.7643108367919922, 1.2633070945739746, 0.9991462826728821, 0.8905456066131592, 0.7821604609489441, 0.7194777131080627, 0.48905131220817566, 0.48157086968421936, 0.3968345522880554, 0.47396141290664673, 0.5062967538833618], \"Total\": [2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.8185672760009766, 3.0302722454071045, 2.2579517364501953, 2.2277302742004395, 2.225062131881714, 2.1428799629211426, 2.1205241680145264, 2.0818676948547363, 2.043134927749634, 1.9489208459854126, 2.5700650215148926, 2.5330214500427246, 2.5330214500427246, 2.5700650215148926, 1.9489208459854126, 2.043134927749634, 2.0818676948547363, 2.1205241680145264, 2.1428799629211426, 2.225062131881714, 2.2277302742004395, 2.2579517364501953, 3.0302722454071045, 3.8185672760009766], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.7128000259399414, -1.9718999862670898, -2.289299964904785, -2.3529999256134033, -2.3589000701904297, -2.5573999881744385, -2.61899995803833, -2.7353999614715576, -2.8673999309539795, -3.287899971008301, -3.1263999938964844, -3.318700075149536, -1.7391999959945679, -1.7963999509811401, -2.1303999423980713, -2.365000009536743, -2.48009991645813, -2.609800100326538, -2.6933999061584473, -3.079400062561035, -3.0947999954223633, -3.2883999347686768, -3.11080002784729, -3.044800043106079], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.31459999084472656, 0.28679999709129333, 0.2635999917984009, 0.21330000460147858, 0.2085999995470047, 0.04769999906420708, -0.0034000000450760126, -0.10140000283718109, -0.21459999680519104, -0.5878999829292297, -0.7031000256538391, -0.8808000087738037, 0.6987000107765198, 0.6269999742507935, 0.569599986076355, 0.28780001401901245, 0.15399999916553497, 0.005799999926239252, -0.08820000290870667, -0.511900007724762, -0.5285000205039978, -0.7354999780654907, -0.8521000146865845, -1.017300009727478]}, \"token.table\": {\"Topic\": [1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1], \"Freq\": [0.480337917804718, 0.480337917804718, 0.8857585191726685, 0.39478543400764465, 0.7895708680152893, 0.4666616916656494, 0.4666616916656494, 0.47158151865005493, 0.47158151865005493, 0.5131044983863831, 0.5131044983863831, 0.8977747559547424, 0.48944392800331116, 0.48944392800331116, 0.7856349945068359, 0.2618783116340637, 0.8988512754440308, 0.3890952169895172, 0.7781904339790344, 0.9900100827217102], \"Term\": [\"computer\", \"computer\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"trees\", \"trees\", \"user\"]}, \"R\": 12, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el112683388575686676029782\", ldavis_el112683388575686676029782_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el112683388575686676029782\", ldavis_el112683388575686676029782_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el112683388575686676029782\", ldavis_el112683388575686676029782_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "1      0.054003  0.0       1        1  63.328152\n",
       "0     -0.054003  0.0       2        1  36.671848, topic_info=         Term      Freq     Total Category  logprob  loglift\n",
       "10      graph  2.000000  2.000000  Default  12.0000  12.0000\n",
       "9       trees  2.000000  2.000000  Default  11.0000  11.0000\n",
       "11     minors  1.000000  1.000000  Default  10.0000  10.0000\n",
       "4      survey  2.000000  2.000000  Default   9.0000   9.0000\n",
       "5      system  3.000000  3.000000  Default   8.0000   8.0000\n",
       "0    computer  2.000000  2.000000  Default   7.0000   7.0000\n",
       "7        user  3.000000  3.000000  Default   6.0000   6.0000\n",
       "2   interface  2.000000  2.000000  Default   5.0000   5.0000\n",
       "8         eps  2.000000  2.000000  Default   4.0000   4.0000\n",
       "1       human  2.000000  2.000000  Default   3.0000   3.0000\n",
       "3    response  2.000000  2.000000  Default   2.0000   2.0000\n",
       "6        time  2.000000  2.000000  Default   1.0000   1.0000\n",
       "5      system  3.312271  3.818567   Topic1  -1.7128   0.3146\n",
       "7        user  2.556311  3.030272   Topic1  -1.9719   0.2868\n",
       "8         eps  1.861117  2.257952   Topic1  -2.2893   0.2636\n",
       "3    response  1.746159  2.227730   Topic1  -2.3530   0.2133\n",
       "6        time  1.736011  2.225062   Topic1  -2.3589   0.2086\n",
       "1       human  1.423402  2.142880   Topic1  -2.5574   0.0477\n",
       "2   interface  1.338364  2.120524   Topic1  -2.6190  -0.0034\n",
       "0    computer  1.191322  2.081868   Topic1  -2.7354  -0.1014\n",
       "4      survey  1.043989  2.043135   Topic1  -2.8674  -0.2146\n",
       "11     minors  0.685614  1.948921   Topic1  -3.2879  -0.5879\n",
       "9       trees  0.805754  2.570065   Topic1  -3.1264  -0.7031\n",
       "10      graph  0.664848  2.533021   Topic1  -3.3187  -0.8808\n",
       "10      graph  1.868173  2.533021   Topic2  -1.7392   0.6987\n",
       "9       trees  1.764311  2.570065   Topic2  -1.7964   0.6270\n",
       "11     minors  1.263307  1.948921   Topic2  -2.1304   0.5696\n",
       "4      survey  0.999146  2.043135   Topic2  -2.3650   0.2878\n",
       "0    computer  0.890546  2.081868   Topic2  -2.4801   0.1540\n",
       "2   interface  0.782160  2.120524   Topic2  -2.6098   0.0058\n",
       "1       human  0.719478  2.142880   Topic2  -2.6934  -0.0882\n",
       "6        time  0.489051  2.225062   Topic2  -3.0794  -0.5119\n",
       "3    response  0.481571  2.227730   Topic2  -3.0948  -0.5285\n",
       "8         eps  0.396835  2.257952   Topic2  -3.2884  -0.7355\n",
       "7        user  0.473961  3.030272   Topic2  -3.1108  -0.8521\n",
       "5      system  0.506297  3.818567   Topic2  -3.0448  -1.0173, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "0         1  0.480338   computer\n",
       "0         2  0.480338   computer\n",
       "8         1  0.885759        eps\n",
       "10        1  0.394785      graph\n",
       "10        2  0.789571      graph\n",
       "1         1  0.466662      human\n",
       "1         2  0.466662      human\n",
       "2         1  0.471582  interface\n",
       "2         2  0.471582  interface\n",
       "11        1  0.513104     minors\n",
       "11        2  0.513104     minors\n",
       "3         1  0.897775   response\n",
       "4         1  0.489444     survey\n",
       "4         2  0.489444     survey\n",
       "5         1  0.785635     system\n",
       "5         2  0.261878     system\n",
       "6         1  0.898851       time\n",
       "9         1  0.389095      trees\n",
       "9         2  0.778190      trees\n",
       "7         1  0.990010       user, R=12, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(goodLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save html file\n",
    "vis = pyLDAvis.gensim.prepare(goodLdaModel, corpus, dictionary)\n",
    "vis = pyLDAvis.prepared_data_to_html(vis)\n",
    "\n",
    "with open(\"LDA_output.html\", \"w\") as file:\n",
    "    file.write(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for topic_id, topic in goodLdaModel.show_topics(num_topics=10,formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['graph',\n",
       "  'trees',\n",
       "  'minors',\n",
       "  'survey',\n",
       "  'computer',\n",
       "  'interface',\n",
       "  'human',\n",
       "  'system',\n",
       "  'time',\n",
       "  'response'],\n",
       " ['system',\n",
       "  'user',\n",
       "  'eps',\n",
       "  'response',\n",
       "  'time',\n",
       "  'human',\n",
       "  'interface',\n",
       "  'computer',\n",
       "  'survey',\n",
       "  'trees']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malletâ€™s version of LDA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Sabeeha\\\\AppData\\\\Local\\\\Temp\\\\9d5505_state.mallet.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-5bfecc308518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'E:\\projects\\mallet-2.0.8\\bin\\mallet'\u001b[0m \u001b[1;31m# update this path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mldamallet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sabeeha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sabeeha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training MALLET LDA with %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;31m# NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;31m# word_topics has replaced wordtopics throughout the code;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sabeeha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mload_word_topics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[0mword2id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrevdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sabeeha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sabeeha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Sabeeha\\\\AppData\\\\Local\\\\Temp\\\\9d5505_state.mallet.gz'"
     ]
    }
   ],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = r'E:\\projects\\mallet-2.0.8\\bin\\mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the optimal number of topics for LDA?\n",
    "My approach to finding the optimal number of topics is to build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
