
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Techniques and definitions__\n",
    "\n",
    "- It is recommended to convert the column from 'object' type to categorical before One Hot Encoding on both train and test sets. Below is how I'd go about doing OHE:\n",
    "\n",
    "- we need to combine test and train data to maintain consistency. for example categorical encoding, if all categories aren't present in both set, they might be labelled differently if done in two sets operations.\n",
    "\n",
    "- __Robustness__ is defined as resistance to outliers in a dataset\n",
    "- __decision boundary__ is a line that separates the target variables into different classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO RESOLVE__\n",
    "\n",
    "- sampling, central limit theorem, p-value, null hypothesis, ANOVA, correlation vs causation, \n",
    "- standard deviation and measures of dispersion, mean vs median, random variables, \n",
    "- expected values and variance, distributions, GLMs, Bayesian stats, etc. Some examples are: -\n",
    "\n",
    "- How best to select a representative sample of search queries from 5 million?\n",
    "- The mean heights of men and women in a population were calculated to be mM and mW. What is the mean height of the total population?\n",
    "- How do you detect if a new observation is an outlier?\n",
    "\n",
    "- Explain the difference between mean and median.\n",
    "\n",
    "- What is the goal of A/B Testing?\n",
    "\n",
    "- What is sampling? Why do we need it? What is stratified sampling?\n",
    "\n",
    "- Review the basic concept of a Normal Distribution.\n",
    "- Learn how to do some basic hypothesis tests. Explain p-values and type I and type II errors.\n",
    "- Explain what are confidence intervals and why they are important.\n",
    "- Explain what is statistical power.\n",
    "- Explain how you would do an A/B test.\n",
    "- Explain what is a bootstrap and how to use it.\n",
    "- Explain the basic concepts of bayesian inference: prior, posterior, etc.\n",
    "-- Explain ANOVA and Chi-Square.\n",
    "- Explain ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is the Central Limit Theorem? Why it's important?__\n",
    "\n",
    "CLT is approximatation under certain condition. We can approximate some distribution with Normal distribution although the distribution is not Normally distributed. it states thats if n = no of sample size is large enough, it follows normal distribution. Sample size equal to or greater than 30 are required for the central limit theorem to hold true.\n",
    "\n",
    "Central Limit Theorem says that the distribution of MEANS is normally distributed. This knowledge allows us to construct error terms based on the area under the curve for the normal distribution for means of ANY distribution… thus we can have confidence intervals on means.\n",
    "\n",
    "Other methods are bootstrapping. The CLT describes exactly how much an increase in n (sample size) reduces sampling error. This in turn tells us about the precision or margin of error for estimates of statistics, such as percentages, from samples. Thus, as the sample size (N) increases the sampling error will decrease\n",
    "\n",
    "For example, if an estimate of 47% (in favor of legalizing marijuana, for example) in a sample of n = 50 has a margin of error of +5% or - 5%,\n",
    "\n",
    "and we increase n to 100,\n",
    "\n",
    "we will find that the margin or error for this percentage has decreased.\n",
    "\n",
    "It is more useful to have a percentage estimate with a small margin of error than with a large margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is the difference between model parameters and hyperparameters?__\n",
    "\n",
    "Hyper-parameters are those which we supply to the model, for example: number of hidden Nodes and Layers,input features, Learning Rate, Activation Function etc in Neural Network, while Parameters are those which would be learned by the machine like Weights and Biases.\n",
    "\n",
    "Model Parameters are something that a model learns on its own. For example, \n",
    "\n",
    "- weights or Coefficients of independent variables in Linear regression model. \n",
    "- Weights or Coefficients of independent variables SVM. \n",
    "- Split points in Decision Tree.\n",
    "\n",
    "Model hyper-parameters are used to optimize the model performance. For example\n",
    "\n",
    "- Kernel and slack in SVM. \n",
    "- Value of K in KNN. \n",
    "- Depth of tree in Decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is Overfitting & Underfitting?__\n",
    "\n",
    "Underfitting refers to not capturing enough patterns in the data. The model performs poorly both in the training and the test set. Overfitting refers: a) capturing noise and b) capturing patterns which do not generalize well to unseen data. The model performs extremely well to the training set but poorly on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. How do you prevent over-fitting when you are creating a statistical model?__\n",
    "\n",
    "__cross-validation__\n",
    "It is a technique used for model validation, i.e. to find out how the results of a statistical analysis will generalize to an independent population. It is mainly used in scenarios where the aim is prediction and one wants to evaluate how accurately a model will perform in practice. The aim of cross-validation is to name a data set to test the model in the training phase in order to limit problems like overfitting and find out how the model will generalize to an independent data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is Akaike Information Criteria?__\n",
    "\n",
    "- Model selection is the process of fitting multiple models on a given dataset and choosing one over all others.\n",
    "\n",
    "- AIC is a measure of relative goodness of fit. AIC is useful for comparing models, but it does not tell you anything about the goodness of fit of a single, isolated model.\n",
    "\n",
    "- Akaike Information Criterion (AIC). Derived from frequentist probability.\n",
    "- Bayesian Information Criterion (BIC). Derived from Bayesian probability.\n",
    "- Minimum Description Length (MDL). Derived from information theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is Poisson distribution ?__\n",
    "\n",
    "Poisson distribution is used to find out the number of events that may happen in a continuous time interval. eg. how many emails may occur at any particular time duration or how many people show up in a queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. Is standard deviation robust to outliers?__\n",
    "\n",
    "A low standard deviation indicates a low spread about the mean while a high standard deviation means the data shows very wide distribution. Extreme values of data points would increase standard deviation as they would be far away from the average value. Thus outliers will affect the value of the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is regularization? What is the difference in the outcome (coefficients) between the L1 and L2 norms?__\n",
    "\n",
    "\n",
    "L1 is used for feature selection, sparsity and less computational cost, whereas L2 is used to fight against multicolinearity. \n",
    "\n",
    "in modern machine learning libraries (for example: scikit-learn), both are used together to serve all purposes simultaneously. This method is called “elastic net regularization”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What are false positives and false negatives?__\n",
    "\n",
    "False positives are those cases in which the negatives are wrongly predicted as positives. For example, predicting that a customer will churn when, in fact, he is not churning.\n",
    "\n",
    "False negatives are those cases in which the positives are wrongly predicted as negatives. For example, predicting that a customer will not churn when, in fact, he churns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What are precision and recall?__\n",
    "\n",
    "Precision is the proportion of true positives out of predicted positives(accuracy of the prediction.) It is also known as the ‘positive predictive value’.\n",
    "\n",
    "- Precision = TP/TP+FP. \n",
    "- Recall is same as the true positive rate (TPR) ie. = TP/TP+FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. Do you suggest that treating a categorical variable as continuous variable would result in a better predictive model?__\n",
    "\n",
    "For better predictions, categorical variable can be considered as a continuous variable only when the variable is ordinal in nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q How to define/select metrics?__\n",
    "\n",
    "This depends on following\n",
    "\n",
    "- Type of task: regression? Classification?\n",
    "- Business goal?\n",
    "- What is the distribution of the target variable?\n",
    "- What metric do we optimize for?\n",
    "\n",
    "Regression: \n",
    "- RMSE (root mean squared error), \n",
    "- MAE (mean absolute error), \n",
    "- WMAE(weighted mean absolute error), \n",
    "- RMSLE (root mean squared logarithmic error)…\n",
    "\n",
    "Classification: \n",
    "- recall, AUC, accuracy, misclassification error, Cohen’s Kappa…\n",
    "\n",
    "Common metrics in regression:\n",
    "\n",
    "Mean Squared Error Vs Mean Absolute Error RMSE gives a relatively high weight to large errors. The RMSE is most useful when large errors are particularly undesirable.\n",
    "The MAE is a linear score: all the individual differences are weighted equally in the average. MAE is more robust to outliers than MSE.\n",
    "RMSE=1n∑ni=1(yi−y^i)2−−−−−−−−−−−−−−√\n",
    "MAE=1n∑ni=1|yi−y^i|\n",
    "\n",
    "Root Mean Squared Logarithmic Error\n",
    "RMSLE penalizes an under-predicted estimate greater than an over-predicted estimate (opposite to RMSE)\n",
    "RMSLE=1n∑ni=1(log(pi+1)−log(ai+1))2−−−−−−−−−−−−−−−−−−−−−−−−−−−√\n",
    "Where pi is the ith prediction, ai the ith actual response, log(b) the natural logarithm of b.\n",
    "\n",
    "Weighted Mean Absolute Error\n",
    "The weighted average of absolute errors. MAE and RMSE consider that each prediction provides equally precise information about the error variation, i.e. the standard variation of the error term is constant over all the predictions. Examples: recommender systems (differences between past and recent products)\n",
    "WMAE=1∑wi∑ni=1wi|yi−y^i|\n",
    "\n",
    "Common metrics in classification:\n",
    "\n",
    "Recall / Sensitivity / True positive rate:\n",
    "High when FN low. Sensitive to unbalanced classes.\n",
    "Sensitivity=TPTP+FN\n",
    "\n",
    "Precision / Positive Predictive Value\n",
    "High when FP low. Sensitive to unbalanced classes.\n",
    "Precision=TPTP+FP\n",
    "\n",
    "Specificity / True Negative Rate\n",
    "High when FP low. Sensitive to unbalanced classes.\n",
    "Specificity=TNTN+FP\n",
    "\n",
    "Accuracy\n",
    "High when FP and FN are low. Sensitive to unbalanced classes (see “Accuracy paradox”)\n",
    "Accuracy=TP+TNTN+TP+FP+FN\n",
    "\n",
    "ROC / AUC\n",
    "ROC is a graphical plot that illustrates the performance of a binary classifier (Sensitivity Vs 1−Specificity or Sensitivity Vs Specificity). They are not sensitive to unbalanced classes.\n",
    "AUC is the area under the ROC curve. Perfect classifier: AUC=1, fall on (0,1); 100% sensitivity (no FN) and 100% specificity (no FP)\n",
    "\n",
    "Logarithmic loss\n",
    "Punishes infinitely the deviation from the true value! It’s better to be somewhat wrong than emphatically wrong!\n",
    "logloss=−1N∑ni=1(yilog(pi)+(1−yi)log(1−pi))\n",
    "\n",
    "Misclassification Rate\n",
    "Misclassification=1n∑iI(yi≠y^i)\n",
    "\n",
    "F1-Score\n",
    "Used when the target variable is unbalanced. F1Score=2Precision×RecallPrecision+Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What are the assumptions required for linear regression? What if some of these assumptions are violated?__\n",
    "\n",
    "- The data used in fitting the model is representative of the population\n",
    "- The true underlying relation between x and y is linear\n",
    "- Variance of the residuals is constant (homoscedastic, not heteroscedastic)\n",
    "- The residuals are independent\n",
    "- The residuals are normally distributed\n",
    "\n",
    "Predict y from x: 1) + 2)\n",
    "Estimate the standard error of predictors: 1) + 2) + 3)\n",
    "Get an unbiased estimation of y from x: 1) + 2) + 3) + 4)\n",
    "Make probability statements, hypothesis testing involving slope and correlation, confidence intervals: 1) + 2) + 3) + 4) + 5)\n",
    "\n",
    "Note:\n",
    "- Common mythology: linear regression doesn’t assume anything about the distributions of x and y\n",
    "- It only makes assumptions about the distribution of the residuals\n",
    "- And this is only needed for statistical tests to be valid\n",
    "- Regression can be applied to many purposes, even if the errors are not normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What are some model performance metrics in Liner Regression?__\n",
    "\n",
    "\n",
    "In regression model, the most commonly known evaluation metrics include:\n",
    "\n",
    "__R-squared (R2)__, which is the proportion of variation in the outcome that is explained by the predictor variables. In multiple regression models, R2 corresponds to the squared correlation between the observed outcome values and the predicted values by the model. The Higher the R-squared, the better the model.\n",
    "\n",
    "__Root Mean Squared Error (RMSE)__, which measures the average error performed by the model in predicting the outcome for an observation. Mathematically, the RMSE is the square root of the mean squared error (MSE), which is the average squared difference between the observed actual outome values and the values predicted by the model. So, MSE = mean((observeds - predicteds)^2) and RMSE = sqrt(MSE). The lower the RMSE, the better the model.\n",
    "\n",
    "__Residual Standard Error (RSE)__, also known as the model sigma, is a variant of the RMSE adjusted for the number of predictors in the model. The lower the RSE, the better the model. In practice, the difference between RMSE and RSE is very small, particularly for large multivariate data.\n",
    "\n",
    "__Mean Absolute Error (MAE)__, like the RMSE, the MAE measures the prediction error. Mathematically, it is the average absolute difference between observed and predicted outcomes, MAE = mean(abs(observeds - predicteds)). MAE is less sensitive to outliers compared to RMSE.\n",
    "\n",
    "The problem with the above metrics, is that they are sensible to the inclusion of additional variables in the model, even if those variables dont have significant contribution in explaining the outcome. Put in other words, including additional variables in the model will always increase the R2 and reduce the RMSE. So, we need a more robust metric to guide the model choice.\n",
    "\n",
    "Concerning R2, there is an adjusted version, called Adjusted R-squared, which adjusts the R2 for having too many variables in the model.\n",
    "\n",
    "Additionally, there are four other important metrics - AIC, AICc, BIC and Mallows Cp - that are commonly used for model evaluation and selection. These are an unbiased estimate of the model prediction error MSE. The lower these metrics, he better the model.\n",
    "\n",
    "AIC stands for (Akaike’s Information Criteria), a metric developped by the Japanese Statistician, Hirotugu Akaike, 1970. The basic idea of AIC is to penalize the inclusion of additional variables to a model. It adds a penalty that increases the error when including additional terms. The lower the AIC, the better the model.\n",
    "AICc is a version of AIC corrected for small sample sizes.\n",
    "BIC (or Bayesian information criteria) is a variant of AIC with a stronger penalty for including additional variables to the model.\n",
    "Mallows Cp: A variant of AIC developed by Colin Mallows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is collinearity and what to do with it? How to remove multicollinearity?__\n",
    "\n",
    "Collinearity/Multicollinearity:\n",
    "- In multiple regression: when two or more variables are highly correlated\n",
    "- They provide redundant information\n",
    "- In case of perfect multicollinearity: β=(XTX)−1XTy doesn’t exist, the design matrix isn’t invertible\n",
    "- It doesn’t affect the model as a whole, doesn’t bias results\n",
    "- The standard errors of the regression coefficients of the affected variables tend to be large\n",
    "- The test of hypothesis that the coefficient is equal to zero may lead to a failure to reject a false null hypothesis of no effect of the explanatory (Type II error)\n",
    "- Leads to overfitting\n",
    "\n",
    "Remove multicollinearity:\n",
    "- Drop some of affected variables\n",
    "- Principal component regression: gives uncorrelated predictors\n",
    "- Combine the affected variables\n",
    "- Ridge regression\n",
    "- Partial least square regression\n",
    "\n",
    "Detection of multicollinearity:\n",
    "- Large changes in the individual coefficients when a predictor variable is added or deleted\n",
    "- Insignificant regression coefficients for the affected predictors but a rejection of the joint\n",
    "hypothesis that those coefficients are all zero (F-test)\n",
    "- VIF: the ratio of variances of the coefficient when fitting the full model divided by the variance of the coefficient when fitted on its own\n",
    "- rule of thumb: VIF>5 indicates multicollinearity\n",
    "- Correlation matrix, but correlation is a bivariate relationship whereas multicollinearity is multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q How to check if the regression model fits the data well?__\n",
    "\n",
    "R squared/Adjusted R squared:\n",
    "- R2=RSStot−RSSresRSStot=RSSregRSStot=1−RSSresRSStot\n",
    "- Describes the percentage of the total variation described by the model\n",
    "- R2 always increases when adding new variables: adjusted R2 incorporates the model’s degrees of freedom\n",
    "\n",
    "F test:\n",
    "- Evaluate the hypothesis Ho: all regression coefficients are equal to zero Vs H1: at least one doesn’t\n",
    "- Indicates that R2 is reliable\n",
    "\n",
    "RMSE:\n",
    "- Absolute measure of fit (whereas R2 is a relative measure of fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is an outlier? Explain how you might screen for outliers and what would you do if you found them in your dataset. Also, explain what an inlier is and how you might screen for them and what would you do if you found them in your dataset?__\n",
    "\n",
    "Outliers:\n",
    "- An observation point that is distant from other observations\n",
    "- Can occur by chance in any distribution\n",
    "- Often, they indicate measurement error or a heavy-tailed distribution\n",
    "- Measurement error: discard them or use robust statistics\n",
    "- Heavy-tailed distribution: high skewness, can’t use tools assuming a normal distribution\n",
    "- Three-sigma rules (normally distributed data): 1 in 22 observations will differ by twice the standard deviation from the mean\n",
    "- Three-sigma rules: 1 in 370 observations will differ by three times the standard deviation from the mean\n",
    "\n",
    "Three-sigma rules example: in a sample of 1000 observations, the presence of up to 5 observations deviating from the mean by more than three times the standard deviation is within the range of what can be expected, being less than twice the expected number and hence within 1 standard deviation of the expected number (Poisson distribution).\n",
    "\n",
    "If the nature of the distribution is known a priori, it is possible to see if the number of outliers deviate significantly from what can be expected. For a given cutoff (samples fall beyond the cutoff with probability p), the number of outliers can be approximated with a Poisson distribution with lambda=pn. Example: if one takes a normal distribution with a cutoff 3 standard deviations from the mean, p=0.3% and thus we can approximate the number of samples whose deviation exceed 3 sigmas by a Poisson with lambda=3\n",
    "\n",
    "Identifying outliers:\n",
    "- No rigid mathematical method\n",
    "- Subjective exercise: be careful\n",
    "- Boxplots\n",
    "- QQ plots (sample quantiles Vs theoretical quantiles)\n",
    "\n",
    "Handling outliers:\n",
    "- Depends on the cause\n",
    "- Retention: when the underlying model is confidently known\n",
    "- Regression problems: only exclude points which exhibit a large degree of influence on the estimated coefficients (Cook’s distance)\n",
    "\n",
    "Inlier:\n",
    "- Observation lying within the general distribution of other observed values\n",
    "- Doesn’t perturb the results but are non-conforming and unusual\n",
    "- Simple example: observation recorded in the wrong unit (°F instead of °C)\n",
    "\n",
    "Identifying inliers:\n",
    "- Mahalanobi’s distance\n",
    "- Used to calculate the distance between two random vectors\n",
    "- Difference with Euclidean distance: accounts for correlations\n",
    "- Discard them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. Is mean imputation of missing data acceptable practice? Why or why not?__\n",
    "\n",
    "Bad practice in general\n",
    "If just estimating means: mean imputation preserves the mean of the observed data\n",
    "Leads to an underestimate of the standard deviation\n",
    "Distorts relationships between variables by “pulling” estimates of the correlation toward zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is the best way to handle missing values in data set?__\n",
    "\n",
    "There is NO best way, each solution/algorithm has their own pros and cons (and you can even mix some of them together to create your own strategy and tune the related parameters to come up one best satisfy your data, there are many research/papers about this topic).\n",
    "\n",
    "For example, Mean Imputation is quick and simple, but it would underestimate the variance and the distribution shape is distorted by replacing NaN with the mean value, while KNN Imputation might not be ideal in a large data set in terms of time complexity, since it iterate over all the data points and perform calculation for each NaN value, and the assumption is that NaN attribute is correlated with other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. How do you handle missing data? What imputation techniques do you recommend?__\n",
    "\n",
    "If data missing at random: deletion has no bias effect, but decreases the power of the analysis by decreasing the effective sample size. Recommended: Knn imputation, Gaussian mixture imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. Give examples of data that does not have a Gaussian distribution, nor log-normal?__\n",
    "\n",
    "- Allocation of wealth among individuals\n",
    "- Values of oil reserves among oil fields (many small ones, a small number of large ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is the difference between loss functions, cost functions and objective function?__\n",
    "\n",
    "- The loss function computes the error for a single training example, while the cost function is the average of the loss functions of the entire training set.\n",
    "\n",
    "- Loss function is usually a function defined on a data point, prediction and label, and measures the penalty.\n",
    "e.g. square loss in liner regression and hinge loss in SVM\n",
    "\n",
    "- Cost function is usually more general. It might be a sum of loss functions over your training set plus some model complexity penalty (regularization)\n",
    "e.g. MSE\n",
    "\n",
    "__Objective Function__\n",
    "\n",
    "- Objective function is the most general term for any function that you optimize(minimize or maximize) during training. \n",
    "- For example, a probability of generating training set in maximum likelihood approach is a well defined objective function, but it is not a loss function nor cost function.\n",
    "- MLE is a type of objective function (which you maximize)\n",
    "- Divergence between classes can be an objective function but it is barely a cost function, unless you define something artificial, like 1-Divergence, and name it a cost\n",
    "- maximize the posterior probabilities (e.g., naive Bayes)\n",
    "- maximize information gain/minimize child node impurities (CART decision tree classification)\n",
    "- minimize a mean squared error cost (or loss) function (CART, decision tree regression, linear regression, adaptive linear neurons, …\n",
    "- maximize log-likelihood or minimize cross-entropy loss (or cost) function\n",
    "- minimize hinge loss (support vector machine) …\n",
    "\n",
    "_A loss function is a part of a cost function which is a type of an objective function._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q Scaling Vs Normalization - What is the difference?__\n",
    "\n",
    "We need scaling mainly for algorithms which internally uses some distance measure technique (say Euclidian Distance. Whereas, Normalization is needed, when comparing populations/phenomena of different size but with the same origin.\n",
    "Scaling just changes the range of your data. This means that you're transforming your data so that it fits within a specific scale, like 0-100 or 0-1. You want to scale data when you're using methods based on measures of how far apart data points, like SVM or KNN. With these algorithms, a change of \"1\" in any numeric feature is given the same importance.\n",
    "\n",
    "For example, you might be looking at the prices of some products in both Yen and US Dollars. One US Dollar is worth about 100 Yen, but if you don't scale your prices methods like SVM or KNN will consider a difference in price of 1 Yen as important as a difference of 1 US Dollar! This clearly doesn't fit with our intuitions of the world. With currency, you can convert between currencies. But what about if you're looking at something like height and weight? It's not entirely clear how many pounds should equal one inch (or how many kilograms should equal one meter).\n",
    "By scaling your variables, you can help compare different variables on equal footing. To help solidify what scaling looks like, let's look at a made-up example. (Don't worry, we'll work with real data in just a second, this is just to help illustrate my point.)\n",
    "\n",
    "In general, you'll only want to normalize your data if you're going to be using a machine learning or statistics technique that assumes your data is normally distributed. Some examples of these include t-tests, ANOVAs, linear regression, linear discriminant analysis (LDA) and Gaussian naive Bayes. (Pro tip: any method with \"Gaussian\" in the name probably assumes normality.)\n",
    "The method were using to normalize here is called the Box-Cox Transformation. Let's take a quick peek at what normalizing some data looks like:\n",
    "\n",
    "\n",
    "__Normalization__\n",
    "As the number of features grows, calculating gradient takes longer to compute. We can speed this up by “normalizing”\n",
    "our input data to ensure all values are within the same range. This is especially important for datasets with high\n",
    "standard deviations or differences in the ranges of the attributes. Our goal now will be to normalize our features so\n",
    "they are all in the range -1 to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation  / Covariance / Association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association__\n",
    "- Categorical - categorical ==> chi square\n",
    "- quantitative - quantitative ==> ANOVA\n",
    "- Quantitative - Quantitative ==> Pearson's correlaation\n",
    "- continuous - descrete ==> one way Anova ( Kruskal Wallis H Test non pararmetric form of one-way anova)\n",
    "- \n",
    "\n",
    "__Variance__\n",
    "- measure of widht of distribution\n",
    "\n",
    "__Covariance__\n",
    "- Covariance is a measure of how changes in one variable are associated with changes in a second variable. Specifically, covariance measures the degree to which two variables are linearly associated.\n",
    "- measuring the variance between two variables \n",
    "- Covariance is used to measure variables that have different units of measurement. \n",
    "- its same as variance when only two variables are compared rather than single random variable with itself\n",
    "- If two variables are independent, their covariance is 0. But, having a covariance of 0 does not imply the variables are independent.\n",
    "- Covariance doesn't really tell you about the strength of the relationship between the two variables, while correlation does\n",
    "- use covariance when direction is not enough\n",
    "\n",
    "__Correlation__\n",
    "- measure of relationship between two variablie\n",
    "- Correlation varies between -1 to +1\n",
    "- Correlation is a function of the covariance. What sets them apart is the fact that correlation values are standardized whereas, covariance values are not.\n",
    "- Correlation is dimensionless. It is a unit-free measure \n",
    "- Correlation analysis is a tool for feature selection. \n",
    "- PCA is one of the application of feature selection.\n",
    "- There are several types of correlation algorithms, here: Correlation (Pearson, Kendall, Spearman)\n",
    "- use the covariance matrix when the variable are on similar scales and the correlation matrix when the scales of the variables differ.\n",
    "- Correlation is a scaled version of covariance that takes on values in [−1,1] with a correlation of ±1 indicating perfect linear association and 0 indicating no linear relationship. This scaling makes correlation invariant to changes in scale of the original variables\n",
    "- If the categorical variable has three or more label, then notion of correlation breaks down\n",
    "- also called as covariance normalized\n",
    "- You would use Correlation when your objective is to determine the general linear relationship between two data series.\n",
    "- Covariance and Correlation are very helpful in understanding the relationship between two continuous variables.\n",
    "- There is no significance of covariance numerical value only sign is useful. Whereas Correlation explains the change in one variable leads how much proportion change in the second variable.\n",
    "\n",
    "- Pearson correlation measures the linear association between continuous variables. \n",
    "- Spearman's rank correlation coefficient can be defined as a special case of Pearson ρ applied to ranked (sorted) variables.\n",
    "- Spearman's correlation is not restricted to linear relationships. \n",
    "\n",
    "__Cross Validation Vs Grid Search__\n",
    "- Cross validation is used for Model selection while grid search is used for parameter selection\n",
    "- Grid serch helps to find optimal combinationof hyperparameter values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is the difference between covariance and correlation?__\n",
    "\n",
    "The covariance is a measure for how two variables are related to each other, i.e., how two variables vary with each other.\n",
    "A covariance of 0 indicates that two variables are totally unrelated. If the covariance is positive, the variables increase in the same direction, and if the covariance is negative, the variables change in opposite directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary Least Squares (OLS) Linear Regression, our goal is to find the line (or hyperplane) that minimizes the vertical offsets. Or, in other words, we define the best-fitting line as the line that minimizes the sum of squared errors (SSE) or mean squared error (MSE) between our target variable (y) and our predicted output over all samples.\n",
    "Now, we can implement a linear regression model for performing ordinary least squares regression using one of the following approaches:\n",
    "Solving the model parameters analytically (closed-form equations)\n",
    "Using an optimization algorithm (Gradient Descent, Stochastic Gradient Descent, Newton's Method, Simplex Method, etc.)\n",
    "\n",
    "\n",
    "__Gradient Descent__ \n",
    "\n",
    "- Gradient descent is an optimization algorithm often used for finding the weights/coefficients of ML algorithms, such as ANN and logistic regression.\n",
    "- The goal of the algorithm is to find model parameters (e.g. coefficients or weights) that minimize the error of the model on the training dataset.\n",
    "- The three main flavors of gradient descent are batch, stochastic, and mini-batch.\n",
    "- Some other optimization algorith are Newton's method, simplex method.\n",
    "\n",
    "__Stochastic Gradient Descent (SGD/onl-line/incremental gradient descent)__\n",
    "\n",
    "- SGD is a variation of the gradient descent algorithm that calculates the error and updates the model for each example in the training dataset.For example, if the training set contains 100 samples then the parameters are updated 100 times\n",
    "\n",
    "__Batch (or Standard) Gradient Descent__\n",
    "Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated.  For example, if the training dataset contains 100 training examples then the parameters of the neural network are updated once. \n",
    "\n",
    "__Mini-batch gradient descent__\n",
    "Mini-batch gradient descent strikes a balance between batch gradient descent and stochastic gradient descent by increasing the number of observations that we select at each iteration. In mini-batch gradient descent, we use a few data points for each gradient update instead of a single point. e.g. say the training set has 100 training examples which is divided into 5 batches with each batch containing 20 training examples. This means that the equation in figure2 will be iterated over 5 times (number of batches).\n",
    "\n",
    "__Batch Gradient Descent Vs Stochastic Gradient Descent__\n",
    "\n",
    "- In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. Both of these techniques are used to find optimal parameters for a model.\n",
    "- There is only one small difference between GD and SGD. Gradient descent calculates the gradient based on the loss function calculated across all training instances, whereas SGD calculates the gradient based on the loss in batches. SGD is useful for large datasets.\n",
    "\n",
    "Thus, if the number of training samples are large, in fact very large, then using gradient descent may take too long because in every iteration when you are updating the values of the parameters, you are running through the complete training set. On the other hand, using SGD will be faster because you use only one training sample and it starts improving itself right away from the first sample.\n",
    "\n",
    "SGD often converges much faster compared to GD but the error function is not as well minimized as in the case of GD. Often in most cases, the close approximation that you get in SGD for the parameter values are enough because they reach the optimal values and keep oscillating there.\n",
    "\n",
    "Choosing a proper learning rate can be difficult. A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A probability distribution is a function that describes the likelihood of obtaining the possible values that a random variable can assume. Probability distributions indicate the likelihood of an event or outcome. The sum of all probabilities for all possible values must equal 1.\n",
    "- Expected Value. The average value of a  random variable.\n",
    "\n",
    "\n",
    "- There are only two possible outcomes of a Bernoulli and Binomial distribution, namely success and failure.\n",
    "- Perform m independent Bernoulli trials. it is knows as Binomial Distribution.\n",
    "-  Bernoulli Distribution is a special case of Binomial Distribution with a single trial(m=1).\n",
    "- Binomial distributions are just sums of Bernoullis \n",
    "\n",
    "\n",
    "Uniform Distribution\n",
    "When you roll a fair die, the outcomes are 1 to 6. The probabilities of getting these outcomes are equally likely and that is the basis of a uniform distribution. Unlike Bernoulli Distribution, all the n number of possible outcomes of a uniform distribution are equally likely.\n",
    "\n",
    "Normal distribution represents the behavior of most of the situations in the universe (That is why it’s called a “normal” distribution. I guess!). The large sum of (small) random variables often turns out to be normally distributed, contributing to its widespread application. Any distribution is known as Normal distribution if it has the following characteristics:\n",
    "\n",
    "The mean, median and mode of the distribution coincide.\n",
    "The curve of the distribution is bell-shaped and symmetrical about the line x=μ.\n",
    "The total area under the curve is 1.\n",
    "Exactly half of the values are to the left of the center and the other half to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is Variance Inflation Facotor(VIF)?__\n",
    "\n",
    "- a way to measure the effect of multicollinearity among your predictors .More variation is bad. If the variance of the coefficients increases, our model isn't going to be as reliable. \n",
    "\n",
    "- Colinearity is the state where two variables are highly correlated and contain similiar information about the variance\n",
    "- multicollinearity is when three or more predictors in your regression are highly correlated\n",
    "- Multicollinearity is dangerous because it can increase the variance of the regression coefficients.\n",
    "- Multicollinearity can rise if the data is collected without and experimental design\n",
    "- The Variance Inflation Factor (VIF) is a measure of colinearity among predictor variables within a multiple regression\n",
    "-  a VIF is > 10, you have high multicollinearity.\n",
    "- Tolerance is the reciprocal of VIF.\n",
    "- VIF = 1 (Not correlated)\n",
    "- 1 < VIF < 5 (Moderately correlated)\n",
    "- VIF >=5 (Highly correlated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What are the assumptions for logistic and linear regression?__\n",
    "\n",
    "- Linearity of residuals, \n",
    "- Independence of residuals, \n",
    "- Normal distribution of residuals, \n",
    "- Equal variance of residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q How do we interpret p-value?__\n",
    "\n",
    "A p-value is the probability of observing a result given a null hypothesis (e.g. no change, no difference, or no result):\n",
    "A p-value is not the probability of the hypothesis being true, given the result.\n",
    "\n",
    "The p-value is interpreted in the context of a pre-chosen significance level, called alpha. A common value for alpha is 0.05, or 5%. It can also be thought of as a confidence level of 95% calculated as (1.0 – alpha).\n",
    "\n",
    "The p-value can be interpreted with the significance level as follows:\n",
    "\n",
    "p-value <= alpha: significant result, reject null hypothesis (H0), distributions differ.\n",
    "p-value > alpha: not significant result, do not reject null hypothesis (H0), distributions same.\n",
    "A significance level of 5% means that there is a 95% likelihood that we will detect a result (reject H0), if there is a result to detect. Put another way, there is a 5% likelihood of finding an effect (reject H0) if there is no effect, called a false positive or more technically a Type I error.\n",
    "\n",
    "- probability of error\n",
    "- a low p-value indicates that the null hypothesis can be rejected\n",
    "- a large p-value suggest that changes in predictor are not associated with changes in response\n",
    "- Significance level (alpha) is the probability of rejecting null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__F test__\n",
    "\n",
    "- F test can be used to answer as do the  sample comes from population of equal variances\n",
    "- variability o fthe process\n",
    "\n",
    "__Skewness__\n",
    "\n",
    "- it measures symmetry in a distribution\n",
    "- skewness == 0 measn normal distribution\n",
    "- scipy.stats.skew\n",
    "- more precisely skewness is a measure of non-symmetry\n",
    "\n",
    "\n",
    "__Kurtosis__\n",
    "\n",
    "- it measures wheather the data is heavily taild right or left\n",
    "- Use histogram to see both kurtosis and skewness\n",
    "- Kurtosis of standard normal distribution is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalizing data technique__\n",
    "\n",
    "- log transformation\n",
    "- box-cox transformation\n",
    "- Square/cube root\n",
    "- reciprocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is the difference between “standardization” and “normalization”?__\n",
    "\n",
    "Standardization refers to scaling a variable that has a Gaussian distribution such that it has a mean of zero and a standard deviation of one.\n",
    "\n",
    "Normalization refers to scaling a variable that has any distribution so that all values are between zero and one.\n",
    "\n",
    "It is possible to normalize after standardizing a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is the difference between a “parameter” and a “hyperparameter”?__\n",
    "\n",
    "Model parameters are internal to the model and learned by the training algorithm.\n",
    "\n",
    "Examples of model parameters are the coefficients in a regression, weights in a neural network, and the split points in a decision tree.\n",
    "\n",
    "The model parameters are the thing saved after training. They are the model.\n",
    "\n",
    "Model hyperparameters are specified by you, the practitioner and often control the learning process. They are parameters that cannot be learned.\n",
    "\n",
    "Examples of model hyperparameters are the number of epochs or training iterations in stochastic gradient descent and the maximum depth of decision trees.\n",
    "\n",
    "The model hyperparameters are found by trial-and-error, by grid/random searching, or by comping examples that have worked in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q Why are some scores like MSE negative in scikit-learn?__\n",
    "\n",
    "Some model evaluation metrics such as mean squared error (MSE) are negative when calculated in scikit-learn.\n",
    "\n",
    "This is confusing, because error scores like MSE cannot actually be negative, with the smallest value being zero or no error.\n",
    "\n",
    "The scikit-learn library has a unified model scoring system where it assumes that all model scores are maximized. In order this system to work with scores that are minimized, like MSE and other measures of error, the sores that are minimized are inverted by making them negative.\n",
    "\n",
    "This can also be seen in the specification of the metric, e.g. ‘neg‘ is used in the name of the metric ‘neg_mean_squared_error‘.\n",
    "\n",
    "When interpreting the negative error scores, you can ignore the sign and use them directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What are Rank Correlation techniques?__\n",
    "\n",
    "Rank correlation is a technique that compares which features correlate with the output.One popular rank correlation method in ML is the Principal Component Analysis. It’s a technique to find patterns in high dimensional data.Naturally, this comes at the expense of accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What Is The Difference Between PCA and PLS (Principal Component Analysis VS. Partial Least Squares)?__\n",
    "\n",
    "__PCA__\n",
    "PCA tries to explain the variance-covariance structure of a data set. Aim is to increase the variance of the features itself, like the loss of information is greatly reduced. PCA is a Dimensionality Reduction algorithm. Both PLS and PCA are used for dimension reduction.\n",
    "\n",
    "__PLS__\n",
    "Partial Least Squares, use the annotated label to maximize inter-class variance. Principal components are pairwise orthogonal. Principal components are focus on maximize correlation.\n",
    "The main difference is that the PCA is unsupervised method and PLS is supervised method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is the difference between LDA and PCA for dimensionality reduction?__\n",
    "\n",
    "Both LDA and PCA are linear transformation techniques: LDA is a supervised whereas PCA is unsupervised -- PCA ignores class labels. We can picture PCA as a technique that finds the directions of maximal variance. LDA makes assumptions about normally distributed classes and equal class covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
