{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Resolve\n",
    "\n",
    "- sampling, central limit theorem, p-value, null hypothesis, ANOVA, correlation vs causation, \n",
    "- standard deviation and measures of dispersion, mean vs median, random variables, \n",
    "- expected values and variance, distributions, GLMs, Bayesian stats, etc. Some examples are: -\n",
    "- How best to select a representative sample of search queries from 5 million?\n",
    "- The mean heights of men and women in a population were calculated to be mM and mW. What is the mean height of the total population?\n",
    "- How do you detect if a new observation is an outlier?\n",
    "- Explain the difference between mean and median.\n",
    "- What is the goal of A/B Testing?\n",
    "- What is sampling? Why do we need it? What is stratified sampling?\n",
    "- Review the basic concept of a Normal Distribution.\n",
    "- Learn how to do some basic hypothesis tests. Explain p-values and type I and type II errors.\n",
    "- Explain what are confidence intervals and why they are important.\n",
    "- Explain what is statistical power.\n",
    "- Explain how you would do an A/B test.\n",
    "- Explain what is a bootstrap and how to use it.\n",
    "- Explain the basic concepts of bayesian inference: prior, posterior, etc.\n",
    "- Explain ANOVA and Chi-Square.\n",
    "- Explain ARIMA.\n",
    "- For which problems will you use L1 penalty, and for which - L2?\n",
    "- Q35 What is the difference between Bayesian Inference and Maximum Likelihood Estimation (MLE)?\n",
    "\n",
    "\n",
    "# NOTES\n",
    "\n",
    "\n",
    "- Precision Metrix : In Stats, precision is the reciproal of variance. Precision matrix is matrix inverse of covariance matrix.\n",
    "- as the number of variable increases in the model, complexity increases, size of coefficients increases ,overfitting may rise, therefore we need regularization techniques\n",
    "- Robustness is defined as resistance to outliers in a dataset\n",
    "\n",
    "- decision boundary is a line that separates the target variables into different classes.\n",
    "\n",
    "- Gradient Descent: A method to find the local minimum of a function. From a point along the direction of gradient to iterational search by a certain step length, until gradient equals zero.\n",
    "\n",
    "- The objective of ML is to minimize the loss function on training dataset. An optimization algorithms can then minimize this loss.\n",
    "\n",
    "- Objective function consist of training loss and regularization i.e. Obj(loss,regularization). Regularization, measures complexity of model or how how complicated the model is.\n",
    "\n",
    "- Training Loss measures how well model fit on training data\n",
    "\n",
    "- Optimizing training loss results in good fit, whereas optimizing regularization encourages simple model.\n",
    "- a simple models means smaller variance.\n",
    "- Overfitting is when a model is trained too well on the training dat\n",
    "- OLS is to linear regression. Maximum likelihood is to logistic regression. Explain the statement.,\"OLS and Maximum likelihood are the methods used by the respective regression methods to approximate the unknown parameter (coefficient) value. In simple words,\n",
    "\n",
    "- Ordinary least square(OLS) is a method used in linear regression which approximates the parameters resulting in minimum distance between actual and predicted values. Maximum Likelihood helps in choosing the the values of parameters which maximizes the likelihood that the parameters are most likely to produce observed data.\n",
    "\n",
    "\n",
    "- Jaccard similarity is not efficient because I have millions of users and items.\n",
    "\n",
    "- It is recommended to convert the column from 'object' type to categorical before One Hot Encoding on both train and test sets. Below is how I'd go about doing OHE:  we need to combine test and train data to maintain consistency. for example categorical encoding, if all categories aren't present in both set, they might be labelled differently if done in two sets operations.\n",
    "\n",
    "- utility function are maximized eg. score whereas cost function are minimized eg. MSE\n",
    "\n",
    "- Matrix factorization gives the recommendation model\n",
    "\n",
    "- Bias (an error) is a pre-assumption of the model. How far off our predictions are from real valueseg weight ( gradient in liner algebra)\n",
    "\n",
    "- Gradient is the steepness of the Linear function.\n",
    "\n",
    "- Data transformation stablizes variance.\n",
    "\n",
    "- k-means clustering is only usable if clusters have convex shapes and every point belongs to exactly one cluster.\n",
    "\n",
    "- LSTM's a family of RNN (Recurrent Neural Network)  are known for sequence prediction, sequence classification\n",
    "\n",
    "- TF-IDF : how important a word in a document is\n",
    "\n",
    "- a contingency table a.k.a crosstab is a frequency table of multivariates\n",
    "\n",
    "- A loss function is a gap between prediction and truth. MSE : Regression , Cross Entropy loss : Classification\n",
    "\n",
    "- DT : Gini performs binary splits whereas chi square can perform two or more splits\n",
    "\n",
    "- chi square test is non - parametric i.e. distribution free\n",
    "\n",
    "- SVM : a model with greater margins are preferred.\n",
    "\n",
    "- SVC: scaling is must if using RBF kernel\n",
    "\n",
    "- feature matrix is instance space\n",
    "\n",
    "__ML Steps__\n",
    "1. Model and objective function ( Liner Regression, Decision Treea)\n",
    "2. Cost Function (MSE, Cross Entropy)\n",
    "3. Optimization function (Adam, Gradient Descent)\n",
    "4. Evaluation Criteria (Accuracy, precision-recall, confusion matrix)\n",
    "\n",
    "- Estimators are abstract class (models in a box)\n",
    "\n",
    "\n",
    "Fetaur importance\n",
    "-  coef_ for linear models\n",
    "- feature_importance_ for tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p- value\n",
    "P-value is used to determine the significance of results after a hypothesis test. P-value helps to draw conclusions and is always between 0 and 1.\n",
    "\n",
    "hypothesis testing\n",
    "- Formulate null and alternative hypothesis\n",
    "- select significance level\n",
    "- select test statistics and calculate its value (eg z-test, chi square)\n",
    "\n",
    "- P- Value > 0.05 denotes weak evidence against the null hypothesis which means the null hypothesis cannot be rejected.\n",
    "- P-value <= 0.05 denotes strong evidence against the null hypothesis which means the null hypothesis can be rejected.\n",
    "- P-value=0.05is the marginal value indicating it is possible to go either way.\n",
    "\n",
    "__Q How do we interpret p-value?__\n",
    "\n",
    "A p-value is the probability of observing a result given a null hypothesis (e.g. no change, no difference, or no result):\n",
    "A p-value is not the probability of the hypothesis being true, given the result.\n",
    "\n",
    "The p-value is interpreted in the context of a pre-chosen significance level, called alpha. A common value for alpha is 0.05, or 5%. It can also be thought of as a confidence level of 95% calculated as (1.0 – alpha).\n",
    "\n",
    "The p-value can be interpreted with the significance level as follows:\n",
    "\n",
    "p-value <= alpha: significant result, reject null hypothesis (H0), distributions differ.\n",
    "p-value > alpha: not significant result, do not reject null hypothesis (H0), distributions same.\n",
    "A significance level of 5% means that there is a 95% likelihood that we will detect a result (reject H0), if there is a result to detect. Put another way, there is a 5% likelihood of finding an effect (reject H0) if there is no effect, called a false positive or more technically a Type I error.\n",
    "\n",
    "- probability of error\n",
    "- a low p-value indicates that the null hypothesis can be rejected\n",
    "- a large p-value suggest that changes in predictor are not associated with changes in response\n",
    "- Significance level (alpha) is the probability of rejecting null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "CLT is approximatation under certain condition. We can approximate some distribution with Normal distribution although the distribution is not Normally distributed. it states thats if n = no of sample size is large enough, it follows normal distribution. Sample size equal to or greater than 30 are required for the central limit theorem to hold true.\n",
    "\n",
    "Central Limit Theorem says that the distribution of MEANS is normally distributed. This knowledge allows us to construct error terms based on the area under the curve for the normal distribution for means of ANY distribution… thus we can have confidence intervals on means.\n",
    "\n",
    "Other methods are bootstrapping. The CLT describes exactly how much an increase in n (sample size) reduces sampling error. This in turn tells us about the precision or margin of error for estimates of statistics, such as percentages, from samples. Thus, as the sample size (N) increases the sampling error will decrease\n",
    "\n",
    "For example, if an estimate of 47% (in favor of legalizing marijuana, for example) in a sample of n = 50 has a margin of error of +5% or - 5%,\n",
    "\n",
    "and we increase n to 100,\n",
    "\n",
    "we will find that the margin or error for this percentage has decreased.\n",
    "\n",
    "It is more useful to have a percentage estimate with a small margin of error than with a large margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "\n",
    "\n",
    "- An observation point that is distant from other observations\n",
    "- Can occur by chance in any distribution\n",
    "- Often, they indicate measurement error or a heavy-tailed distribution\n",
    "- Measurement error: discard them or use robust statistics\n",
    "- Heavy-tailed distribution: high skewness, can’t use tools assuming a normal distribution\n",
    "- Three-sigma rules (normally distributed data): 1 in 22 observations will differ by twice the standard deviation from the mean\n",
    "- Three-sigma rules: 1 in 370 observations will differ by three times the standard deviation from the mean\n",
    "\n",
    "Three-sigma rules example: in a sample of 1000 observations, the presence of up to 5 observations deviating from the mean by more than three times the standard deviation is within the range of what can be expected, being less than twice the expected number and hence within 1 standard deviation of the expected number (Poisson distribution).\n",
    "\n",
    "If the nature of the distribution is known a priori, it is possible to see if the number of outliers deviate significantly from what can be expected. For a given cutoff (samples fall beyond the cutoff with probability p), the number of outliers can be approximated with a Poisson distribution with lambda=pn. Example: if one takes a normal distribution with a cutoff 3 standard deviations from the mean, p=0.3% and thus we can approximate the number of samples whose deviation exceed 3 sigmas by a Poisson with lambda=3\n",
    "\n",
    "Identifying outliers:\n",
    "- No rigid mathematical method\n",
    "- Subjective exercise: be careful\n",
    "- Boxplots\n",
    "- QQ plots (sample quantiles Vs theoretical quantiles)\n",
    "\n",
    "Handling outliers:\n",
    "- Depends on the cause\n",
    "- Retention: when the underlying model is confidently known\n",
    "- Regression problems: only exclude points which exhibit a large degree of influence on the estimated coefficients (Cook’s distance)\n",
    "\n",
    "Inlier:\n",
    "- Observation lying within the general distribution of other observed values\n",
    "- Doesn’t perturb the results but are non-conforming and unusual\n",
    "- Simple example: observation recorded in the wrong unit (°F instead of °C)\n",
    "\n",
    "Identifying inliers:\n",
    "- Mahalanobi’s distance\n",
    "- Used to calculate the distance between two random vectors\n",
    "- Difference with Euclidean distance: accounts for correlations\n",
    "- Discard them\n",
    "\n",
    "__Q. Is standard deviation robust to outliers?__\n",
    "\n",
    "A low standard deviation indicates a low spread about the mean while a high standard deviation means the data shows very wide distribution. Extreme values of data points would increase standard deviation as they would be far away from the average value. Thus outliers will affect the value of the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting & Underfitting\n",
    "\n",
    "Underfitting refers to not capturing enough patterns in the data. The model performs poorly both in the training and the test set. Overfitting refers: a) capturing noise and b) capturing patterns which do not generalize well to unseen data. The model performs extremely well to the training set but poorly on the test set.\n",
    "\n",
    "\n",
    "__Q  How can you overcome Overfitting?__\n",
    "\n",
    "Regularization: add a regularizer or a penalty term.\n",
    "\n",
    "Cross Validation: Simple cross validation; S-fold cross validation; Leave-one-out cross validation. It is a technique used for model validation, i.e. to find out how the results of a statistical analysis will generalize to an independent population. It is mainly used in scenarios where the aim is prediction and one wants to evaluate how accurately a model will perform in practice. The aim of cross-validation is to name a data set to test the model in the training phase in order to limit problems like overfitting and find out how the model will generalize to an independent data set.\n",
    "\n",
    "__Q What is regularization? What is the difference in the outcome (coefficients) between the L1 and L2 norms?__\n",
    "\n",
    "L1 is used for feature selection, sparsity and less computational cost, whereas L2 is used to fight against multicolinearity. \n",
    "\n",
    "in modern machine learning libraries (for example: scikit-learn), both are used together to serve all purposes simultaneously. This method is called “elastic net regularization”.\n",
    "\n",
    "__Q What is Regularization and what kind of problems does regularization solve?__\n",
    "\n",
    "A central problem in machine learning is how to make an algorithm that will perform well not just on the training data, but also on new inputs. Many strategies used in machine learning are explicitly  designed to reduce the test error, possibly at the expense of increased training error. These strategies are known collectively as regularization. Briefly, regularization is any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.\n",
    "\n",
    "__Q How to reduce the variance in a model?__\n",
    "\n",
    "The easiest and most common way of reducing the variance in a ML model is by applying techniques that limit its effective capacity, i.e. regularization.\n",
    "\n",
    "The most common forms of regularization are parameter norm penalties, which limit the parameter updates during the training phase; early stopping, which cuts the training short; pruning for tree-based algorithms; dropout for neural networks, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "There is NO best way, each solution/algorithm has their own pros and cons (and you can even mix some of them together to create your own strategy and tune the related parameters to come up one best satisfy your data, there are many research/papers about this topic).\n",
    "\n",
    "For example, Mean Imputation is quick and simple, but it would underestimate the variance and the distribution shape is distorted by replacing NaN with the mean value, while KNN Imputation might not be ideal in a large data set in terms of time complexity, since it iterate over all the data points and perform calculation for each NaN value, and the assumption is that NaN attribute is correlated with other attributes.\n",
    "\n",
    "__Q. How do you handle missing data? What imputation techniques do you recommend?__\n",
    "\n",
    "If data missing at random: deletion has no bias effect, but decreases the power of the analysis by decreasing the effective sample size. Recommended: Knn imputation, Gaussian mixture imputation\n",
    "\n",
    "__Q. Is mean imputation of missing data acceptable practice? Why or why not?__\n",
    "\n",
    "Bad practice in general\n",
    "If just estimating means: mean imputation preserves the mean of the observed data\n",
    "Leads to an underestimate of the standard deviation\n",
    "Distorts relationships between variables by “pulling” estimates of the correlation toward zero\n",
    "\n",
    "__Q. When should one use median, as opposed to the mean or average?__\n",
    "\n",
    "It really depends on the distribution of the data and the question you are trying to address.\n",
    "\n",
    "for a symmetrical data mean and median is same\n",
    "\n",
    "Fore skewed daa, we take median as it is less susceptible to outliers and extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling vs Normalization\n",
    "\n",
    "We need scaling mainly for algorithms which internally uses some distance measure technique (say Euclidian Distance. Whereas, Normalization is needed, when comparing populations/phenomena of different size but with the same origin.\n",
    "Scaling just changes the range of your data. This means that you're transforming your data so that it fits within a specific scale, like 0-100 or 0-1. You want to scale data when you're using methods based on measures of how far apart data points, like SVM or KNN. With these algorithms, a change of \"1\" in any numeric feature is given the same importance.\n",
    "\n",
    "For example, you might be looking at the prices of some products in both Yen and US Dollars. One US Dollar is worth about 100 Yen, but if you don't scale your prices methods like SVM or KNN will consider a difference in price of 1 Yen as important as a difference of 1 US Dollar! This clearly doesn't fit with our intuitions of the world. With currency, you can convert between currencies. But what about if you're looking at something like height and weight? It's not entirely clear how many pounds should equal one inch (or how many kilograms should equal one meter).\n",
    "By scaling your variables, you can help compare different variables on equal footing. To help solidify what scaling looks like, let's look at a made-up example. (Don't worry, we'll work with real data in just a second, this is just to help illustrate my point.)\n",
    "\n",
    "In general, you'll only want to normalize your data if you're going to be using a machine learning or statistics technique that assumes your data is normally distributed. Some examples of these include t-tests, ANOVAs, linear regression, linear discriminant analysis (LDA) and Gaussian naive Bayes. (Pro tip: any method with \"Gaussian\" in the name probably assumes normality.)\n",
    "The method were using to normalize here is called the Box-Cox Transformation. Let's take a quick peek at what normalizing some data looks like:\n",
    "\n",
    "\n",
    "__Normalization__\n",
    "As the number of features grows, calculating gradient takes longer to compute. We can speed this up by “normalizing”\n",
    "our input data to ensure all values are within the same range. This is especially important for datasets with high\n",
    "standard deviations or differences in the ranges of the attributes. Our goal now will be to normalize our features so\n",
    "they are all in the range -1 to 1.\n",
    "\n",
    "\n",
    "__Q What is the difference between “standardization” and “normalization”?__\n",
    "\n",
    "Standardization refers to scaling a variable that has a Gaussian distribution such that it has a mean of zero and a standard deviation of one.\n",
    "\n",
    "Normalization refers to scaling a variable that has any distribution so that all values are between zero and one.\n",
    "\n",
    "It is possible to normalize after standardizing a variable.\n",
    "\n",
    "__Q What are Normalizing data technique__\n",
    "\n",
    "- log transformation\n",
    "- box-cox transformation\n",
    "- Square/cube root\n",
    "- reciprocal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters and hyperparameters\n",
    "\n",
    "Hyper-parameters are those which we supply to the model, for example: number of hidden Nodes and Layers,input features, Learning Rate, Activation Function etc in Neural Network, while Parameters are those which would be learned by the machine like Weights and Biases.\n",
    "\n",
    "Model Parameters are something that a model learns on its own. For example, \n",
    "\n",
    "- weights or Coefficients of independent variables in Linear regression model. \n",
    "- Weights or Coefficients of independent variables SVM. \n",
    "- Split points in Decision Tree.\n",
    "\n",
    "Model hyper-parameters are used to optimize the model performance. For example\n",
    "\n",
    "- Kernel and slack in SVM. \n",
    "- Value of K in KNN. \n",
    "- Depth of tree in Decision trees.\n",
    "\n",
    "__Q What is the difference between a “parameter” and a “hyperparameter”?__\n",
    "\n",
    "Model parameters are internal to the model and learned by the training algorithm.\n",
    "\n",
    "Examples of model parameters are the coefficients in a regression, weights in a neural network, and the split points in a decision tree.\n",
    "\n",
    "The model parameters are the thing saved after training. They are the model.\n",
    "\n",
    "Model hyperparameters are specified by you, the practitioner and often control the learning process. They are parameters that cannot be learned.\n",
    "\n",
    "Examples of model hyperparameters are the number of epochs or training iterations in stochastic gradient descent and the maximum depth of decision trees.\n",
    "\n",
    "The model hyperparameters are found by trial-and-error, by grid/random searching, or by comping examples that have worked in the past.\n",
    "\n",
    "__Q What does cross-validation do?__\n",
    "\n",
    "Cross validation ensures that data is not overfitted and helps to evaluate models. Example optimum number of neighbours in KNN Classification.\n",
    "\n",
    "- holdout method\n",
    "- k-fold cross validation\n",
    "- leave one out CV\n",
    "- bootstrap methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Ordinary Least Squares (OLS) Linear Regression, our goal is to find the line (or hyperplane) that minimizes the vertical offsets. Or, in other words, we define the best-fitting line as the line that minimizes the sum of squared errors (SSE) or mean squared error (MSE) between our target variable (y) and our predicted output over all samples.\n",
    "Now, we can implement a linear regression model for performing ordinary least squares regression using one of the following approaches:\n",
    "Solving the model parameters analytically (closed-form equations)\n",
    "Using an optimization algorithm (Gradient Descent, Stochastic Gradient Descent, Newton's Method, Simplex Method, etc.)\n",
    "\n",
    "\n",
    "__Gradient Descent__ \n",
    "\n",
    "- Gradient descent is an optimization algorithm often used for finding the weights/coefficients of ML algorithms, such as ANN and logistic regression.\n",
    "- The goal of the algorithm is to find model parameters (e.g. coefficients or weights) that minimize the error of the model on the training dataset.\n",
    "- The three main flavors of gradient descent are batch, stochastic, and mini-batch.\n",
    "- Some other optimization algorith are Newton's method, simplex method.\n",
    "\n",
    "__Stochastic Gradient Descent (SGD/onl-line/incremental gradient descent)__\n",
    "\n",
    "- SGD is a variation of the gradient descent algorithm that calculates the error and updates the model for each example in the training dataset.For example, if the training set contains 100 samples then the parameters are updated 100 times\n",
    "\n",
    "__Batch (or Standard) Gradient Descent__\n",
    "Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated.  For example, if the training dataset contains 100 training examples then the parameters of the neural network are updated once. \n",
    "\n",
    "__Mini-batch gradient descent__\n",
    "Mini-batch gradient descent strikes a balance between batch gradient descent and stochastic gradient descent by increasing the number of observations that we select at each iteration. In mini-batch gradient descent, we use a few data points for each gradient update instead of a single point. e.g. say the training set has 100 training examples which is divided into 5 batches with each batch containing 20 training examples. This means that the equation in figure2 will be iterated over 5 times (number of batches).\n",
    "\n",
    "__Batch Gradient Descent Vs Stochastic Gradient Descent__\n",
    "\n",
    "- In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. Both of these techniques are used to find optimal parameters for a model.\n",
    "- There is only one small difference between GD and SGD. Gradient descent calculates the gradient based on the loss function calculated across all training instances, whereas SGD calculates the gradient based on the loss in batches. SGD is useful for large datasets.\n",
    "\n",
    "Thus, if the number of training samples are large, in fact very large, then using gradient descent may take too long because in every iteration when you are updating the values of the parameters, you are running through the complete training set. On the other hand, using SGD will be faster because you use only one training sample and it starts improving itself right away from the first sample.\n",
    "\n",
    "SGD often converges much faster compared to GD but the error function is not as well minimized as in the case of GD. Often in most cases, the close approximation that you get in SGD for the parameter values are enough because they reach the optimal values and keep oscillating there.\n",
    "\n",
    "Choosing a proper learning rate can be difficult. A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric  vs nonparametric learning algorithm\n",
    "\n",
    "non-parametric does not mean that they have NO parameters\n",
    "\n",
    "in a parametric model, we have a finite number of parameters, and in nonparametric models, the number of parameters is (potentially) infinite. Or in other words, in nonparametric models, the complexity of the model grows with the number of training data; in parametric models, we have a fixed number of parameters (or a fixed structure if you will).\n",
    "\n",
    "Linear models such as linear regression, logistic regression, and linear Support Vector Machines are typical examples of a parametric \"learners;\" here, we have a fixed size of parameters (the weight coefficient.) In contrast, K-nearest neighbor, decision trees, or RBF kernel SVMs are considered as non-parametric learning algorithms since the number of parameters grows with the size of the training set. -- K-nearest neighbor and decision trees, that makes sense, but why is an RBF kernel SVM non-parametric whereas a linear SVM is parametric? In the RBF kernel SVM, we construct the kernel matrix by computing the pair-wise distances between the training points, which makes it non-parametric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall vs precision\n",
    "\n",
    "Recall is a measure of completeness whereas Precision is a measure of exactness\n",
    "\n",
    "Recall tells you how much of the 1's you can find.\n",
    "Precision tells you how much junk there is in your predicted 1's.\n",
    "\n",
    "Precision is about being precise. In common English, being precise means: if you give an answer, the answer will very likely be correct. So even if you answered only one question, and you answered this question correctly, you are 100% precise.\n",
    "\n",
    "Recall (as opposed to precision) is not so much about answering questions correctly but more about answering all questions that have answer \"true\" with the answer \"true\". So if we simply always answer \"true\", we have 100% recall.\n",
    "\n",
    "__Q When is precision more important over recall?__\n",
    "\n",
    "\n",
    "__Recall or precision__\n",
    "\n",
    "-The number of opportunities is small (if there were only 10 good apples, then you would be unlikely to find 5 good ones with a recall rate of only 20%)\n",
    "-There are significant differences between opportunities (if some apples are better than others, then a recall rate of 20% is enough to get 5 good apples, but they aren't necessarily going to be the best apples)\n",
    "\n",
    "\n",
    "We have thousands of free customers registering in our website every week. The call center team wants to call them all, but it is imposible, so they ask me to select those with good chances to be a buyer (with high temperature is how we refer to them). We don't care to call a guy that is not going to buy (so precision is not important) but for us is very important that all of them with high temperature are always in my selection, so they don't go without buying. That means that my model needs to have a high recall, no matter if the precision goes to hell.\n",
    "\n",
    "Let us say that a machine learning model is created to predict whether a certain day is a good day to launch satellites or not based on the weather.\n",
    "\n",
    "If the model accidentally predicts that a good day to launch satellites is bad (false negative), we miss the chance to launch. This is not such a big deal.\n",
    "\n",
    "However, if the model predicts that it is a good day, but it is actually a bad day to launch the satellites(false positive) then the satellites may be destroyed and the cost of damages will be in the billions.\n",
    "\n",
    "This is a case where precision is more important than recall.\n",
    "\n",
    "\n",
    "PREcision is to PREgnancy tests as reCALL is to CALL center.\n",
    "With a pregnancy test, the test manufacturer needs to be sure that a positive result means the woman is really pregnant.\n",
    "Email Spam detection:This is one of the example where Precision is more important than Recall.\n",
    "\n",
    "\n",
    "When we have imbalanced class and we need high true positives, precision is prefered over recall. because precision has no false negative in its formula\n",
    "\n",
    "__Q Can you cite some examples where both false positive and false negatives are equally important?__\n",
    "\n",
    "In the banking industry giving loans is the primary source of making money but at the same time if \n",
    "your repayment rate is not good you will not make any profit, rather you will risk huge losses.\n",
    "\n",
    "Banks don’t want to lose good customers and at the same point of time they don’t want to acquire \n",
    "bad customers. In this scenario both the false positives and false negatives become very important \n",
    "to measure.\n",
    "\n",
    "__Q Can you cite some examples where both false positive and false negatives are equally important?__\n",
    "\n",
    "In the banking industry giving loans is the primary source of making money but at the same time if \n",
    "your repayment rate is not good you will not make any profit, rather you will risk huge losses.\n",
    "\n",
    "Banks don’t want to lose good customers and at the same point of time they don’t want to acquire \n",
    "bad customers. In this scenario both the false positives and false negatives become very important \n",
    "to measure.\n",
    "\n",
    "__Q Is it better to have too many false negatives or too many false positives?__\n",
    "\n",
    "It depends on the situation, for example, if we use the model for cancer detection, FN(False Negative)\n",
    "is more serious than FP(False Positive) because a FN could be verified in futher check, but\n",
    "FP maybe will let a patient be missed and delay the best treatment period.\n",
    "\n",
    "__Q Is higher recall better?__\n",
    "\n",
    "a high precision means that an algorithm returned more relevant results, while high recall means that an algorithm returned most of the relevant results.\n",
    "\n",
    "A system with high precision but low recall returns very few results, but most of its predicted labels are correct when compared to the training labels. \n",
    "\n",
    "An ideal system with high precision and high recall will return many results, with all results labeled correctly.\n",
    "\n",
    "\n",
    "in the medical community, a false negative is usually more disastrous than a false positive for preliminary diagnoses.\n",
    "For rare cancer data modeling, anything that doesn't account for false-negatives is a crime. Recall is a better measure than precision.\n",
    "\n",
    "For YouTube recommendations, false-negatives is less of a concern. Precision is better here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions in Liner and Logistics Regression\n",
    "\n",
    "__Q What are the assumptions for logistic and linear regression?__\n",
    "\n",
    "- Linearity of residuals, \n",
    "- Independence of residuals, \n",
    "- Normal distribution of residuals, \n",
    "- Equal variance of residuals\n",
    "\n",
    "__Q What are the assumptions required for linear regression? What if some of these assumptions are violated?__\n",
    "\n",
    "- The data used in fitting the model is representative of the population\n",
    "- The true underlying relation between x and y is linear\n",
    "- Variance of the residuals is constant (homoscedastic, not heteroscedastic)\n",
    "- The residuals are independent\n",
    "- The residuals are normally distributed\n",
    "\n",
    "Predict y from x: 1) + 2)\n",
    "Estimate the standard error of predictors: 1) + 2) + 3)\n",
    "Get an unbiased estimation of y from x: 1) + 2) + 3) + 4)\n",
    "Make probability statements, hypothesis testing involving slope and correlation, confidence intervals: 1) + 2) + 3) + 4) + 5)\n",
    "\n",
    "Note:\n",
    "- Common mythology: linear regression doesn’t assume anything about the distributions of x and y\n",
    "- It only makes assumptions about the distribution of the residuals\n",
    "- And this is only needed for statistical tests to be valid\n",
    "- Regression can be applied to many purposes, even if the errors are not normally distributed\n",
    "\n",
    "__Q How to check if the regression model fits the data well?__\n",
    "\n",
    "R squared/Adjusted R squared:\n",
    "- R2=RSStot−RSSresRSStot=RSSregRSStot=1−RSSresRSStot\n",
    "- Describes the percentage of the total variation described by the model\n",
    "- R2 always increases when adding new variables: adjusted R2 incorporates the model’s degrees of freedom\n",
    "\n",
    "F test:\n",
    "- Evaluate the hypothesis Ho: all regression coefficients are equal to zero Vs H1: at least one doesn’t\n",
    "- Indicates that R2 is reliable\n",
    "\n",
    "RMSE:\n",
    "- Absolute measure of fit (whereas R2 is a relative measure of fit)\n",
    "\n",
    "__F test__\n",
    "\n",
    "- F test can be used to answer as do the  sample comes from population of equal variances\n",
    "- variability o fthe process\n",
    "\n",
    "__Skewness__\n",
    "\n",
    "- it measures symmetry in a distribution\n",
    "- skewness == 0 measn normal distribution\n",
    "- scipy.stats.skew\n",
    "- more precisely skewness is a measure of non-symmetry\n",
    "\n",
    "\n",
    "__Kurtosis__\n",
    "\n",
    "- it measures wheather the data is heavily taild right or left\n",
    "- Use histogram to see both kurtosis and skewness\n",
    "- Kurtosis of standard normal distribution is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution\n",
    "\n",
    "_Q What is the significance of distribution?__\n",
    "\n",
    "The distribution of a statistical data set (or a population) is a listing / function showing all the possible values (or intervals) of the data and how often they occur. \n",
    "\n",
    "When a distribution of categorical data is organized, you see the number or percentage of individuals in each group\n",
    "Think about a die. It has six sides, numbered from 1 to 6\n",
    "\n",
    "For example, the normal distribution comes up almost everywhere due to the Central Limit Theorem, Student's t distribution is the bread and butter of basic statistical hypothesis testing (and probably the most used and abused distribution in the medical research), Poisson distribution is the basic counting process that happens to be super useful and versatile in modelling real-world applications, and so on.\n",
    "\n",
    "## Lognormal distribution vs Power law distribution?\n",
    "\n",
    "\n",
    "__log normal__\n",
    "\n",
    "It is a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable X is log-normally distributed, then Y = ln(X) has a normal distribution.\n",
    "\n",
    "In economics, there is evidence that the income of 97%–99% of the population is distributed log-normally.(The distribution of higher-income individuals follows a Pareto distribution).\n",
    "\n",
    "__power law__\n",
    "\n",
    "The power law (also called the scaling law) states that a relative change in one quantity results in a proportional relative change in another. The simplest example of the law in action is a square; if you double the length of a side (say, from 2 to 4 inches) then the area will quadruple (from 4 to 16 inches squared). A power law distribution has the form Y = k Xα, where:\n",
    "\n",
    "X and Y are variables of interest,\n",
    "α is the law’s exponent,\n",
    "k is a constant.\n",
    "Any inverse relationship like Y = X-1 is also a power law, because a change in one quantity results in a negative change in another.\n",
    "\n",
    "The power law can be used to describe a phenomenon where a small number of items is clustered at the top of a distribution (or at the bottom), taking up 95% of the resources. In other words, it implies a small amount of occurrences is common, while larger occurrences are rare. For example, where the distribution of income is concerned, there are very few billionaires; the bulk of the population holds very modest nest eggs.\n",
    "\n",
    "Distribution of income,\n",
    "Magnitude of earthquakes,\n",
    "Size of cities according to population,\n",
    "Size of corporations,\n",
    "Trading volumes on the stock market,\n",
    "word frequencies.\n",
    "\n",
    "\n",
    "## Probability Distribution Function (PDF) and Probability Mass function (PMF)\n",
    "\n",
    "- A probability distribution is a list of outcomes and their associated probabilities. eg. probability distribution of a dice (1,2,3,4,5,6 each with p(X=x)= /6.\n",
    "\n",
    "- A function that represents a discrete probability distribution is called a probability mass function.\n",
    "- A function that represents a continuous probability distribution is called a probability density function.\n",
    "\n",
    "- PDF/PMF that returns probability i.e. values lies between 0 and 1. A PDF must be integrated over an interval to yield a probability.\n",
    "\n",
    "- PMF take account of only discrete random variables. Thus they give value of P(X=x) whereas PDF take account of continuous random variables. Thus they give value of P(2<x<4), which is of course done via integration except for normal or log-normal distributions where the z table is more easy and usually used.\n",
    "\n",
    "- Probability distribution function takes account of both PMF (discrete rv) and PDF (continuous rv).\n",
    "- Discrete case: Probability Mass Function (PMF)\n",
    "- Continuous case: Probability Density Function (PDF)\n",
    "- Both cases: Cumulative distribution function (CDF)\n",
    "\n",
    "- PMF is preferred when Probability at every x value is interest of study. \n",
    "- PDF is preferred when We wish to model a collected data with a continuous function, by using few parameters such as mean to speculate the population distribution.\n",
    "\n",
    "\n",
    "## Probability Distributions\n",
    "A probability distribution is a function that describes the likelihood of obtaining the possible values that a random variable can assume. Probability distributions indicate the likelihood of an event or outcome. The sum of all probabilities for all possible values must equal 1.\n",
    "- Expected Value. The average value of a  random variable.\n",
    "\n",
    "\n",
    "- There are only two possible outcomes of a Bernoulli and Binomial distribution, namely success and failure.\n",
    "- Perform m independent Bernoulli trials. it is knows as Binomial Distribution.\n",
    "-  Bernoulli Distribution is a special case of Binomial Distribution with a single trial(m=1).\n",
    "- Binomial distributions are just sums of Bernoullis \n",
    "\n",
    "\n",
    "## Uniform Distribution\n",
    "When you roll a fair die, the outcomes are 1 to 6. The probabilities of getting these outcomes are equally likely and that is the basis of a uniform distribution. Unlike Bernoulli Distribution, all the n number of possible outcomes of a uniform distribution are equally likely.\n",
    "\n",
    "## Normal distribution \n",
    "represents the behavior of most of the situations in the universe (That is why it’s called a “normal” distribution. I guess!). The large sum of (small) random variables often turns out to be normally distributed, contributing to its widespread application. Any distribution is known as Normal distribution if it has the following characteristics:\n",
    "\n",
    "- The mean, median and mode of the distribution coincide.\n",
    "- The curve of the distribution is bell-shaped and symmetrical about the line x=μ.\n",
    "- The total area under the curve is 1.\n",
    "- Exactly half of the values are to the left of the center and the other half to the right.\n",
    "\n",
    "__Q. What is Poisson distribution ?__\n",
    "\n",
    "Poisson distribution is used to find out the number of events that may happen in a continuous time interval. eg. how many emails may occur at any particular time duration or how many people show up in a queue.\n",
    "\n",
    "__Q. Give examples of data that does not have a Gaussian distribution, nor log-normal?__\n",
    "\n",
    "- Allocation of wealth among individuals\n",
    "- Values of oil reserves among oil fields (many small ones, a small number of large ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex vs Non-Convex Optimization \n",
    "\n",
    "__Convex__ \n",
    "\n",
    "- Property : strictly convex functions have a unique global minimum,\n",
    "- linear regression/ Ridge regression, with Tikhonov regularisation, etc\n",
    "- sparse linear regression with L1 regularisation, such as lasso\n",
    "- support vector machines\n",
    "- parameter estimation in linear-Gaussian time series (Kalman filter and friends)\n",
    "- The typical cost functions you encounter (cross entropy, absolute loss, least squares) are designed to be convex.\n",
    "- A concave function is the negative of a convex function. Take −x2, for example\n",
    "\n",
    "\n",
    "__non-convex__\n",
    "\n",
    "- a Non-convex functions may have several local minima, Therefore, in a non-convex problem, there is usually no way to test if the solution the best solution. eg. neural networks, maximum likelihood mixtures of Gaussians\n",
    "\n",
    "- Linear algorithms (linear regression, logistic regression etc) will give you convex solutions, that is they will converge. When using neural nets with hidden layers however, you are no longer guaranteed a convex solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction methods\n",
    "\n",
    "Since there are so many different approaches, let's break it down to \"feature selection\" and \"feature extraction.\"\n",
    "\n",
    "__Feature Selection : L1 regularization (e.g., Logistic regression) and sparsity__\n",
    "\n",
    "- variance thresholds\n",
    "- recursive feature elimination based on the weights of linear models\n",
    "- random forests / extra trees and feature importance (calculated as average information gain)\n",
    "- sequential forward/backward selection\n",
    "- genetic algorithms\n",
    "- exhaustive search\n",
    "\n",
    "__Feature extraction:__\n",
    "\n",
    "- Principal Component Analysis (PCA), unsupervised, returns axes of maximal variance given the constraint that those axes are orthogonal to each other\n",
    "- Linear Discriminant Analysis (LDA; not to be confused with Latent Dirichlett Allocation), supervised, returns axes that maximizes class separability (same constraint that axes are also orthogonal); and another article: Linear Discriminant Analysis bit by bit\n",
    "- kernel PCA: uses kernel trick to transform non-linear data to a feature space were samples may be linearly separable (in contrast, LDA and PCA are linear transformation techniques\n",
    "- supervised PCA\n",
    "- and many more non-linear transformation techniques, which you can find nicely summarized here: Nonlinear dimensionality reduction\n",
    "\n",
    "__So, which technique should we use?__\n",
    "\n",
    "This also follows the \"No Lunch Theorem\" principle in some sense: there is no method that is always superior; it depends on your dataset. Intuitively, LDA would make more sense than PCA if you have a linear classification task, but empirical studies showed that it is not always the case. Although kernel PCA can separate concentric circles, it fails to unfold the Swiss Rroll, for example; here, locally linear embedding (LLE) would be more appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions, cost functions and objective function\n",
    "\n",
    "- The loss function computes the error for a single training example, while the cost function is the average of the loss functions of the entire training set.\n",
    "\n",
    "- Loss function is usually a function defined on a data point, prediction and label, and measures the penalty.\n",
    "e.g. square loss in liner regression and hinge loss in SVM\n",
    "\n",
    "- Cost function is usually more general. It might be a sum of loss functions over your training set plus some model complexity penalty (regularization)\n",
    "e.g. MSE\n",
    "\n",
    "__Objective Function__\n",
    "\n",
    "- Objective function is the most general term for any function that you optimize(minimize or maximize) during training. \n",
    "- For example, a probability of generating training set in maximum likelihood approach is a well defined objective function, but it is not a loss function nor cost function.\n",
    "- MLE is a type of objective function (which you maximize)\n",
    "- Divergence between classes can be an objective function but it is barely a cost function, unless you define something artificial, like 1-Divergence, and name it a cost\n",
    "- maximize the posterior probabilities (e.g., naive Bayes)\n",
    "- maximize information gain/minimize child node impurities (CART decision tree classification)\n",
    "- minimize a mean squared error cost (or loss) function (CART, decision tree regression, linear regression, adaptive linear neurons, …\n",
    "- maximize log-likelihood or minimize cross-entropy loss (or cost) function\n",
    "- minimize hinge loss (support vector machine) …\n",
    "\n",
    "_A loss function is a part of a cost function which is a type of an objective function._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF vs Histogram\n",
    "\n",
    "- Hitogram is frequency estimate techinque while PDF is a density estimate.\n",
    "- a histogram involves discrete data (individual bins or classes), whereas a PDF involves continuous data (a smooth curve). \n",
    "\n",
    "- the empirical distribution (i.e. the histogram) is used to describe sample whereas pdf is used to describe the hypothesized underlying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q What is Euclidean distance in terms of machine learning?__\n",
    "\n",
    "It is just a distance measure between a pair of samples p and q in an n-dimensional feature space:\n",
    "\n",
    "\n",
    "For example, picture it as a \"straight, connecting\" line in a 2D feature space:\n",
    "\n",
    "\n",
    "\n",
    "The Euclidean is often the \"default\" distance used in e.g., K-nearest neighbors (classification) or K-means (clustering) to find the \"k closest points\" of a particular sample point. \n",
    "\n",
    "Another prominent example is hierarchical clustering, agglomerative clustering (complete and single linkage) where you want to find the distance between clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q How can we convert continuous variable to categorical variable__\n",
    "\n",
    "Using discretization of data such as entropy (Expected Information) based binning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q How to check if dataset is balanced or not?__\n",
    "\n",
    "by plotting histogram of dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q When to use Ensemble learning?__\n",
    "\n",
    "when single learner overfits i.e. bias-variance. There are two types of ensemble learing viz bagging and boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q.How would you design a recommendation system (like amazon)?__\n",
    "\n",
    "A Collaborative filtering is the most common strategy for recommendation systems. You see user A buys these things and user B also bought those things but user B bought this other thing too so let's show that thing to User A.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. What is Akaike Information Criteria?__\n",
    "\n",
    "- Model selection is the process of fitting multiple models on a given dataset and choosing one over all others.\n",
    "\n",
    "- AIC is a measure of relative goodness of fit. AIC is useful for comparing models, but it does not tell you anything about the goodness of fit of a single, isolated model.\n",
    "\n",
    "- Akaike Information Criterion (AIC). Derived from frequentist probability.\n",
    "- Bayesian Information Criterion (BIC). Derived from Bayesian probability.\n",
    "- Minimum Description Length (MDL). Derived from information theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q. Do you suggest that treating a categorical variable as continuous variable would result in a better predictive model?__\n",
    "\n",
    "For better predictions, categorical variable can be considered as a continuous variable only when the variable is ordinal in nature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
